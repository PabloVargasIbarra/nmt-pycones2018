{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt-pycones.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "abQ_-CccPWjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Machine Translation with Attention. PyconES 2018. <p>\n",
        " *Pablo Vargas Ibarra*\n"
      ]
    },
    {
      "metadata": {
        "id": "f-RGq0yVPu9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero nos aseguramos que estamos utilizando Python 3 con GPU."
      ]
    },
    {
      "metadata": {
        "id": "Tm0_8VHYXALH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a530b34-5a16-4977-c949-d8190e4b992b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "fna4g3zyPLps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a34bfe7-352a-4c3c-f1d8-66ca0fe24535"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.3 (default, Oct  3 2017, 21:45:48) \\n[GCC 7.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "R_uLrDSdLKyL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importamos los paquetes y cargamos las funciones necesarias paa el notebook."
      ]
    },
    {
      "metadata": {
        "id": "Ra3vl3WyLYoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4b3ee960-892c-48fe-b837-10d34d7b3cd2"
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.layers import Bidirectional, Concatenate, Dot, Input, LSTM, RepeatVector, Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.activations import softmax\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gFtPLOczKEta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_npy_from_url(url):\n",
        "    \"\"\"\n",
        "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
        "    input string's characters in the \"vocab\"\n",
        "    \n",
        "    Arguments:\n",
        "    url -- string input url\n",
        "    \n",
        "    Returns:\n",
        "    rep -- numpy array\n",
        "    \"\"\"\n",
        "    with urllib.request.urlopen(url) as url:\n",
        "        with open('tmp.npy', 'wb') as f:\n",
        "            f.write(url.read())\n",
        "    rep = np.load('tmp.npy')\n",
        "    return rep\n",
        "  \n",
        "\n",
        "def string_to_int(string, length, vocab):\n",
        "    \"\"\"\n",
        "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
        "    input string's characters in the \"vocab\"\n",
        "    \n",
        "    Arguments:\n",
        "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
        "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
        "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
        "    \n",
        "    Returns:\n",
        "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
        "    \"\"\"\n",
        "    \n",
        "    string = string.lower()\n",
        "    string = string.replace(',','')\n",
        "    \n",
        "    if len(string) > length:\n",
        "        string = string[:length]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, vocab['UNK']), string))\n",
        "    if len(string) < length:\n",
        "        rep += [vocab['#']] * (length - len(string))\n",
        "    return rep\n",
        "\n",
        "def int_to_string(ints, inv_vocab):\n",
        "    \"\"\"\n",
        "    Output a machine readable list of characters based on a list of indexes in the machine's vocabulary\n",
        "    \n",
        "    Arguments:\n",
        "    ints -- list of integers representing indexes in the machine's vocabulary\n",
        "    inv_vocab -- dictionary mapping machine readable indexes to machine readable characters \n",
        "    \n",
        "    Returns:\n",
        "    l -- list of characters corresponding to the indexes of ints thanks to the inv_vocab mapping\n",
        "    \"\"\"\n",
        "    \n",
        "    l = [inv_vocab[i] for i in ints]\n",
        "    return l\n",
        "\n",
        "def plot_attention_map(model, input_vocabulary, inv_output_vocabulary, text, n_s, num_layer, Tx, Ty):\n",
        "    \"\"\"\n",
        "    Plot the attention map.\n",
        "  \n",
        "    \"\"\"\n",
        "    attention_map = np.zeros((10, 28))\n",
        "    Ty, Tx = attention_map.shape\n",
        "    \n",
        "    s0 = np.zeros((1, n_s))\n",
        "    c0 = np.zeros((1, n_s))\n",
        "    layer = model.layers[num_layer]\n",
        "\n",
        "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 28))\n",
        "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
        "\n",
        "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
        "    r = f([encoded, s0, c0])\n",
        "    \n",
        "    for t in range(Ty):\n",
        "        for t_prime in range(Tx):\n",
        "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
        "\n",
        "    prediction = model.predict([encoded, s0, c0])\n",
        "    \n",
        "    predicted_text = []\n",
        "    for i in range(len(prediction)):\n",
        "        predicted_text.append(int(np.argmax(prediction[i], axis=-1)))\n",
        "        \n",
        "    predicted_text = list(predicted_text)\n",
        "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
        "    text_ = list(text)\n",
        "    \n",
        "    # get the lengths of the string\n",
        "    input_length = len(text)\n",
        "    output_length = Ty\n",
        "    \n",
        "    # Plot the attention_map\n",
        "    # plt.clf();\n",
        "    f = plt.figure(figsize=(8, 8.5));\n",
        "    ax = f.add_subplot(1, 1, 1);\n",
        "\n",
        "    # add image\n",
        "    i = ax.imshow(attention_map, interpolation='nearest', cmap=\"Greys\");\n",
        "\n",
        "    # add colorbar\n",
        "    # cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "    cbaxes = f.add_axes([0.2, 0.1, 0.6, 0.2]);\n",
        "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal');\n",
        "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2);\n",
        "\n",
        "    # add labels\n",
        "    ax.set_yticks(range(output_length));\n",
        "    ax.set_yticklabels(predicted_text[:output_length]);\n",
        "\n",
        "    ax.set_xticks(range(input_length));\n",
        "    ax.set_xticklabels(text_[:input_length], rotation=45);\n",
        "\n",
        "    ax.set_xlabel('Input Sequence');\n",
        "    ax.set_ylabel('Output Sequence');\n",
        "\n",
        "    # add grid and legend\n",
        "    ax.grid();\n",
        "    return attention_map\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDPbanLAMCbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.Traducción de fechas en formato máquina"
      ]
    },
    {
      "metadata": {
        "id": "ke6iYoBIL95J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El modelo que se va a contruir puede ser utilizado para traducir de un lenguaje a otro, por ejemplo del inglés a francés. Sin embargo, la traducción de texto involucra la utilización de conjuntos de datos muy grandes y un tiempo largo de computo incluso utilizando GPUs. Se va a simplificar la traducción a sólo fechas con el objetivo de poder experimentar en un ordenador convencional. <p> <p>\n",
        "La red tomará como input fechas escritas con diferentes formatos (ej: \"the 29th of August 1958\", \"9 mayo 1998\", \"1998-05-09\") y traducirlas a su formato máquina asociado (YYYY-MM-DD)"
      ]
    },
    {
      "metadata": {
        "id": "Obl4nWGoMaxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 - Dataset"
      ]
    },
    {
      "metadata": {
        "id": "_pocnQ7rMdRq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Entrenaremos el modelo sobre un conjunto de datos con 20000 fechas sin formato definido a su equivalente en formato máquina. Aproximadamente 10000 están escritas en castellano y las otras 10000 en inglés. <p>\n",
        " Cargamos los siguientes datos ya calculados:\n",
        "- `dataset`: un array con  (fechas formato humano, fechas formato máquina)\n",
        "- `input_vocab`: diccionario en Python que mapea todos los caracteres del vocabulario humano a un valor entero\n",
        "- `output_vocab`: diccionario en Python que mapea todos los caracteres del vocabulario en formato fecha máquina a un valor entero\n",
        "- `inv_output_vocab`: el diccionario inverso a output_bocab\n",
        "- `X`: fechas en formato humano procesadas tal que cada caracter está mapeado al entero asociado en el vocabulario (input_vocab). Cada secuencia tiene una longitud aumentada con el caracter especial \"pad\" (#).\n",
        "- `Y`: fechas en formato humano procesadas de manera análoga utilizando su vocabulario (output_vocab). \n",
        "- `Xoh`: one-hot version de X.\n",
        "- `Yoh`: one-hot version de Y. "
      ]
    },
    {
      "metadata": {
        "id": "WA0RnkYlNjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9b02146e-03de-4fac-af1c-335d7702e172"
      },
      "cell_type": "code",
      "source": [
        "dataset = load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/data.npy')\n",
        "print('Primeros 5 ejemplos de entrenamiento:')\n",
        "print(dataset[:5])\n",
        "X =  load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/Xt.npy')\n",
        "Y = load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/Yt.npy')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Primeros 5 ejemplos de entrenamiento:\n",
            "[['9 mayo 1998' '1998-05-09']\n",
            " ['10.09.70' '1970-09-10']\n",
            " ['4/28/90' '1990-04-28']\n",
            " ['jueves enero 26 1995' '1995-01-26']\n",
            " ['lunes marzo 7 1983' '1983-03-07']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0KxEKffiL78h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "77b24092-b0e3-4cb2-cf47-4a88e2f51bcf"
      },
      "cell_type": "code",
      "source": [
        "input_vocab = load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/X_tok2idx.npy').item()\n",
        "output_vocab = load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/Y_tok2idx.npy').item()\n",
        "inv_output_vocab = load_npy_from_url('https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/data/Y_idx2tok.npy').item()\n",
        "Xoh = to_categorical(X, len(input_vocab))\n",
        "Yoh = to_categorical(Y, len(output_vocab))\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (20000, 28)\n",
            "Y.shape: (20000, 10)\n",
            "Xoh.shape: (20000, 28, 38)\n",
            "Yoh.shape: (20000, 10, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFIK1c0gL24t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tx = 28   # Tamaño de la secuencia de entrada\n",
        "Ty = 10   # Tamaño de la secuencia de salida\n",
        "m = 20000 # Número de ejemplos de entrenamiento"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eRpQnLEOIK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 Neural machine translation model with attention"
      ]
    },
    {
      "metadata": {
        "id": "4RNGbDswOLfr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Supongamos que tenemos que traducir la secuencia, **\"jueves 26 de enero de 1995\"** a **\"1995-01-26\"**. Durante el proceso de lectura vamos enfocando la atención en partes de la secuencia de entrada para ir realizando la traducción en la secuencia de salida. El modelo que se implementa siguiente intenta simular este mecanismo de atención con la siguiente arquitectura de redes neuronales."
      ]
    },
    {
      "metadata": {
        "id": "afL8Ct4kOPrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](http://localhost:8888/files/nmt-pycones2018/nmt-images/attn.png)"
      ]
    },
    {
      "metadata": {
        "id": "l3odZYihOXnT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las ecuaciones que definen el mecanismo de atención son las siguientes:\n",
        "$$e^{<i,j>} = v_{a}^{T}\\tanh\\big({W_{a}s_{i-1} + U_{a}h_{j}}\\big)$$ <p>\n",
        "$$\\alpha^{<i,j>} = \\dfrac{exp(e^{<i,j>})}{\\sum_{k=1}^{T_x}exp(e^{<i,k>})}$$ \n",
        "$$context^{<i>} = \\sum_{j = 0}^{T_x} \\alpha^{<i,j>}h^{<j>}$$\n",
        "<sub>**D. Bahdanau, K. Cho, and Y. Bengio. Neural Machine Translation by Jointly Learning to Align and Translate. (2014)**<sub>"
      ]
    },
    {
      "metadata": {
        "id": "s3pRyCfHOoJn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El contexto es una suma ponderada por los parámetros del modelo de atención de los \"hidden states\" de la bidireccional LSTM. Esto será el input de la LSTM final junto con el hidden, cell state de la anterior capa. Estos pesos deberán sumar uno y para ello utilizamos la función softmax propia siguiente:"
      ]
    },
    {
      "metadata": {
        "id": "aRbldud_OrKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax_attention(x, axis=1):\n",
        "    return softmax(x, axis=axis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBd9H_YsOwCa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las operaciones que se realizan para calcular las variables e pueden verse como capas densas de redes neuronales sin el termino \"bias\". Además de que para cada output puede vectorizarse la operación concatenando $s_{i-1}, h_{j}$ <p> Los parámetros asociados al modelo de atención serán compartidos por todas las capas, para ello utilizamos variables globales de Keras."
      ]
    },
    {
      "metadata": {
        "id": "zYqWRnBVOu4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "repeator = RepeatVector(Tx, name='repeat_s') \n",
        "concatenator = Concatenate(axis=-1, name='concat_s_h')\n",
        "tanh_layer = Dense(10, activation = \"tanh\", use_bias=False, name='tanh_layer')\n",
        "v_layer = Dense(1, activation = \"linear\", use_bias=False, \n",
        "                kernel_initializer=\"zeros\", name='v_layer')\n",
        "softmax_layer = Activation(softmax_attention, name='attention_weights') \n",
        "context_layer = Dot(axes = 1, name='context_layer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DLMTPcClPHi2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_step_attention(h, s_prev):\n",
        "    \"\"\"\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "    \n",
        "    Arguments:\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "    \n",
        "    Returns:\n",
        "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
        "    \"\"\"\n",
        "    \n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([h, s_prev])\n",
        "    e = v_layer(tanh_layer(concat))\n",
        "    alphas = softmax_layer(e)\n",
        "    context = context_layer([alphas, h])\n",
        "    \n",
        "    return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGIcrZFLQNkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creamos una función que genera el modelo completo."
      ]
    },
    {
      "metadata": {
        "id": "IH5-YaQ9QRex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(Tx, Ty, n_h, n_s, input_vocab_size, output_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_a -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
        "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Inicializamos los valoes de entrada de la post_attention_LSTM\n",
        "    X = Input(shape=(Tx, input_vocab_size), name='input_X')\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Outputs del modelo\n",
        "    outputs = []\n",
        "    \n",
        "    # Creamos cada una de las capas de la red neuronal\n",
        "    pre_attention_BiLSTM_cell = Bidirectional(LSTM(n_h, return_sequences=True))\n",
        "    post_attention_LSTM_cell = LSTM(n_s, return_state = True, name='post-attention-LSTM')\n",
        "    output_layer = Dense(output_vocab_size, activation='softmax', name='softmax_output')\n",
        "    \n",
        "    \n",
        "    # Primera capa que recibe como input el vector X,\n",
        "    h = pre_attention_BiLSTM_cell(X)\n",
        "    \n",
        "    # Iteramos sobre la secencia del output para calcular el contexto y el output.\n",
        "    for t in range(0, Ty):\n",
        "        \n",
        "        context = one_step_attention(h, s)\n",
        "        s, _, c = post_attention_LSTM_cell(context, initial_state=[s, c])\n",
        "        out = output_layer(s)\n",
        "        outputs.append(out)\n",
        "    \n",
        "    # Creamos el modelo pasandole como argumento los inputs y los outputs\n",
        "    model = Model(inputs=[X, s0, c0], outputs = outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXZdurB6SYtE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definimos el modelo y sus hiperparámetros. Mostramos el resumen de cada una de las capas y sus dimensiones."
      ]
    },
    {
      "metadata": {
        "id": "jlCPKnMwSX7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2591
        },
        "outputId": "20b2efa4-32c8-4b9e-bde9-b3d40e772db3"
      },
      "cell_type": "code",
      "source": [
        "n_h = 48 # Número de hidden units cada una de las dos pre-attention pertenecientes a la BiLSTM.\n",
        "n_s = 96   # Número de hidden units de la post-attention LSTM\n",
        "model = model(Tx, Ty, n_h, n_s, len(input_vocab), len(output_vocab))\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_X (InputLayer)            (None, 28, 38)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 (None, 96)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 28, 96)       33408       input_X[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_s (RepeatVector)         (None, 28, 96)       0           s0[0][0]                         \n",
            "                                                                 post-attention-LSTM[0][0]        \n",
            "                                                                 post-attention-LSTM[1][0]        \n",
            "                                                                 post-attention-LSTM[2][0]        \n",
            "                                                                 post-attention-LSTM[3][0]        \n",
            "                                                                 post-attention-LSTM[4][0]        \n",
            "                                                                 post-attention-LSTM[5][0]        \n",
            "                                                                 post-attention-LSTM[6][0]        \n",
            "                                                                 post-attention-LSTM[7][0]        \n",
            "                                                                 post-attention-LSTM[8][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concat_s_h (Concatenate)        (None, 28, 192)      0           bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[0][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[1][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[2][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[3][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[4][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[5][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[6][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[7][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[8][0]                   \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 repeat_s[9][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tanh_layer (Dense)              (None, 28, 10)       1920        concat_s_h[0][0]                 \n",
            "                                                                 concat_s_h[1][0]                 \n",
            "                                                                 concat_s_h[2][0]                 \n",
            "                                                                 concat_s_h[3][0]                 \n",
            "                                                                 concat_s_h[4][0]                 \n",
            "                                                                 concat_s_h[5][0]                 \n",
            "                                                                 concat_s_h[6][0]                 \n",
            "                                                                 concat_s_h[7][0]                 \n",
            "                                                                 concat_s_h[8][0]                 \n",
            "                                                                 concat_s_h[9][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "v_layer (Dense)                 (None, 28, 1)        10          tanh_layer[0][0]                 \n",
            "                                                                 tanh_layer[1][0]                 \n",
            "                                                                 tanh_layer[2][0]                 \n",
            "                                                                 tanh_layer[3][0]                 \n",
            "                                                                 tanh_layer[4][0]                 \n",
            "                                                                 tanh_layer[5][0]                 \n",
            "                                                                 tanh_layer[6][0]                 \n",
            "                                                                 tanh_layer[7][0]                 \n",
            "                                                                 tanh_layer[8][0]                 \n",
            "                                                                 tanh_layer[9][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Activation)  (None, 28, 1)        0           v_layer[0][0]                    \n",
            "                                                                 v_layer[1][0]                    \n",
            "                                                                 v_layer[2][0]                    \n",
            "                                                                 v_layer[3][0]                    \n",
            "                                                                 v_layer[4][0]                    \n",
            "                                                                 v_layer[5][0]                    \n",
            "                                                                 v_layer[6][0]                    \n",
            "                                                                 v_layer[7][0]                    \n",
            "                                                                 v_layer[8][0]                    \n",
            "                                                                 v_layer[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "context_layer (Dot)             (None, 1, 96)        0           attention_weights[0][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[1][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[2][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[3][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[4][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[5][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[6][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[7][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[8][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "                                                                 attention_weights[9][0]          \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 (None, 96)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "post-attention-LSTM (LSTM)      [(None, 96), (None,  74112       context_layer[0][0]              \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 context_layer[1][0]              \n",
            "                                                                 post-attention-LSTM[0][0]        \n",
            "                                                                 post-attention-LSTM[0][2]        \n",
            "                                                                 context_layer[2][0]              \n",
            "                                                                 post-attention-LSTM[1][0]        \n",
            "                                                                 post-attention-LSTM[1][2]        \n",
            "                                                                 context_layer[3][0]              \n",
            "                                                                 post-attention-LSTM[2][0]        \n",
            "                                                                 post-attention-LSTM[2][2]        \n",
            "                                                                 context_layer[4][0]              \n",
            "                                                                 post-attention-LSTM[3][0]        \n",
            "                                                                 post-attention-LSTM[3][2]        \n",
            "                                                                 context_layer[5][0]              \n",
            "                                                                 post-attention-LSTM[4][0]        \n",
            "                                                                 post-attention-LSTM[4][2]        \n",
            "                                                                 context_layer[6][0]              \n",
            "                                                                 post-attention-LSTM[5][0]        \n",
            "                                                                 post-attention-LSTM[5][2]        \n",
            "                                                                 context_layer[7][0]              \n",
            "                                                                 post-attention-LSTM[6][0]        \n",
            "                                                                 post-attention-LSTM[6][2]        \n",
            "                                                                 context_layer[8][0]              \n",
            "                                                                 post-attention-LSTM[7][0]        \n",
            "                                                                 post-attention-LSTM[7][2]        \n",
            "                                                                 context_layer[9][0]              \n",
            "                                                                 post-attention-LSTM[8][0]        \n",
            "                                                                 post-attention-LSTM[8][2]        \n",
            "__________________________________________________________________________________________________\n",
            "softmax_output (Dense)          (None, 11)           1067        post-attention-LSTM[0][0]        \n",
            "                                                                 post-attention-LSTM[1][0]        \n",
            "                                                                 post-attention-LSTM[2][0]        \n",
            "                                                                 post-attention-LSTM[3][0]        \n",
            "                                                                 post-attention-LSTM[4][0]        \n",
            "                                                                 post-attention-LSTM[5][0]        \n",
            "                                                                 post-attention-LSTM[6][0]        \n",
            "                                                                 post-attention-LSTM[7][0]        \n",
            "                                                                 post-attention-LSTM[8][0]        \n",
            "                                                                 post-attention-LSTM[9][0]        \n",
            "==================================================================================================\n",
            "Total params: 110,517\n",
            "Trainable params: 110,517\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qLA14x9ESrPK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El modelo tiene 110517 parámetros. Se dividen a grandes rasgos en:\n",
        "- Bi-LSTM de entrada (33408)\n",
        "- Attention (1930)\n",
        "- LSTM de salida (74112)\n",
        "- Softmax output (1067)"
      ]
    },
    {
      "metadata": {
        "id": "BfI4mpP_SuP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aplicaremos el algoritmo de optimización Adam siendo la función objetivo la entropia sobre las 11 clases. Mostramos en cada iteración la métrica \"accuracy\"."
      ]
    },
    {
      "metadata": {
        "id": "DWU0EMRCTErV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=0.005, decay=0.01)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6kDcWkBTPa7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tomamos el hidden state, cell state de la post-attention LSTM como el vector de ceros. <p> Convertimos el output Y en un tensor de dimensiones `(Ty, m, len(output_vocab))`"
      ]
    },
    {
      "metadata": {
        "id": "-YgOoifTTU-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjt1V7LrTZ94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El modelo ha sido entrenado durante 20 epochs y cada batch tiene 100 ejemplos de entrenamiento. <p>\n",
        "La máquina consta de una GPU \"K80\" (Google Colab). El entrenamiento dura unos 15 minutos.\n",
        " Para ahorrar tiempo cargamos unos pesos ya entrenados."
      ]
    },
    {
      "metadata": {
        "id": "StLRufAYmjZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Codigo para entrenar el modelo\n",
        "\n",
        "# model.fit([Xoh, s0, c0], outputs, epochs=20, batch_size=100) # Código para entrenar el modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZT_zo7tTcu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cargamos los pesos\n",
        "\n",
        "url = 'https://raw.github.com/PabloVargasIbarra/nmt-pycones2018/master/weights/weights_nmt.h5'\n",
        "with urllib.request.urlopen(url) as url:\n",
        "        with open('weights.h5', 'wb') as f:\n",
        "            f.write(url.read())\n",
        "model.load_weights('weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLYmL_5QY2kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.Aplicación del modelo sobre ejemplos"
      ]
    },
    {
      "metadata": {
        "id": "fjZo8KBUYyqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "10a57c75-b9c9-40e5-d882-a62eef438eda"
      },
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 2009', '21th of August 2016', '10 julio 2007', \n",
        "            'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 marzo 2001']\n",
        "for example in EXAMPLES:\n",
        "    source = string_to_int(example, Tx, input_vocab)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocab)), source)))\n",
        "    source = source.reshape(1, 28, 38)\n",
        "    prediction = model.predict([source, s0, c0])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_output_vocab[int(i)] for i in prediction]\n",
        "    \n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source: 3 May 1979\n",
            "output: 1979-05-03\n",
            "source: 5 April 2009\n",
            "output: 2009-04-05\n",
            "source: 21th of August 2016\n",
            "output: 2016-08-22\n",
            "source: 10 julio 2007\n",
            "output: 2007-07-10\n",
            "source: Saturday May 9 2018\n",
            "output: 2018-05-09\n",
            "source: March 3 2001\n",
            "output: 2001-03-03\n",
            "source: March 3rd 2001\n",
            "output: 2001-03-03\n",
            "source: 1 marzo 2001\n",
            "output: 2001-03-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FdJTykY_beC7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Visualizar los pesos de la atención"
      ]
    },
    {
      "metadata": {
        "id": "OdvDDL4Ebs8e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Si observamos las capas de la red neuronal, la número 7 es la asociada a los pesos de la atención."
      ]
    },
    {
      "metadata": {
        "id": "L8GMcYNxTXxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "454921a1-0eea-49ca-f8bd-574409d8964c"
      },
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.topology.InputLayer at 0x7f3e202f0278>,\n",
              " <keras.engine.topology.InputLayer at 0x7f3e93926160>,\n",
              " <keras.layers.wrappers.Bidirectional at 0x7f3e202e3b00>,\n",
              " <keras.layers.core.RepeatVector at 0x7f3e202f0f28>,\n",
              " <keras.layers.merge.Concatenate at 0x7f3e202f0c50>,\n",
              " <keras.layers.core.Dense at 0x7f3e202e3198>,\n",
              " <keras.layers.core.Dense at 0x7f3e202e3320>,\n",
              " <keras.layers.core.Activation at 0x7f3e202e3470>,\n",
              " <keras.layers.merge.Dot at 0x7f3e202e3438>,\n",
              " <keras.engine.topology.InputLayer at 0x7f3e202e35f8>,\n",
              " <keras.layers.recurrent.LSTM at 0x7f3e202e3ba8>,\n",
              " <keras.layers.core.Dense at 0x7f3e202d12b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "28FvWP8Ob1V4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "9f1f83c6-68ab-4bf8-acd7-dde1d8b9bf22"
      },
      "cell_type": "code",
      "source": [
        "example = \"11 diciemb 2007\"\n",
        "attention_map = plot_attention_map(model=model, input_vocabulary=input_vocab, inv_output_vocabulary=inv_output_vocab, \n",
        "                                   text=example, num_layer=7, n_s=n_s, Tx=Tx, Ty=Ty);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFxCAYAAABJMmAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3e3bd7fb38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9z1oAtgUk7Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f4eb7bb6-ad76-4197-90f5-a1a73aeabd18"
      },
      "cell_type": "code",
      "source": [
        "example = \"10 de febrero de 2011\"\n",
        "attention_map = plot_attention_map(model=model, input_vocabulary=input_vocab, inv_output_vocabulary=inv_output_vocab, \n",
        "                                   text=example, num_layer=7, n_s=n_s, Tx=Tx, Ty=Ty);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFxCAYAAABJMmAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzgAAmAzhDACAyRDOAACYzP8DxGKax4/hFrQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3e0ad165f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jhQxptLRdqoK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### References \n",
        "- I. Goodfellow, Y. Bengio, & A. Courville (2016). Deep Learning. MIT Press. http://www.deeplearningbook.org \n",
        "- A. Ng (2017). Deep Learning Specialization. Coursera. https://www.coursera.org/specializations/deep-learning \n",
        "- D. Bahdanau, K. Cho, and Y. Bengio (2014). Neural Machine Translation by Jointly Learning to Align and Translate. https://arxiv.org/abs/1409.0473\n",
        "- HSE (2018). Natual Language Processing. Coursera. https://www.coursera.org/learn/language-processing \n",
        "- Fast.ai Lesson 1 on Google Colab. https://www.kdnuggets.com/2018/02/fast-ai-lesson-1-google-colab-free-gpu.html\n",
        "- Google Colab Free GPU Tutorial. https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d"
      ]
    }
  ]
}